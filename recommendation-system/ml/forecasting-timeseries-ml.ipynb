{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc6d4eda",
   "metadata": {},
   "source": [
    "# AutoML: Train \"the best\" Time-Series Forecasting model for Retail Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f23d42",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure ML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c55927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "# Suppress OpenTelemetry warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Overriding of current\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Attempting to instrument\")\n",
    "\n",
    "# Suppress Azure SDK telemetry logging\n",
    "logging.getLogger(\"azure.core.pipeline.policies.http_logging_policy\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"azure.identity\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"opentelemetry\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea94c1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "from azure.ai.ml import automl\n",
    "from azure.ai.ml import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c9e64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "credential = AzureCliCredential()\n",
    "ml_client = None\n",
    "try:\n",
    "    subscription_id = \"57123c17-af1a-4ec2-9494-a214fb148bf4\"\n",
    "    resource_group = \"admin-rg\"\n",
    "    workspace = \"ml-demo-wksp-wus-01\"\n",
    "    ml_client = MLClient(credential, subscription_id, resource_group, workspace)\n",
    "except Exception as ex:\n",
    "    print(\"Ex:\", ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c350bf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to: ml-demo-wksp-wus-01 (westus)\n"
     ]
    }
   ],
   "source": [
    "# Verify connection\n",
    "ws = ml_client.workspaces.get(ml_client.workspace_name)\n",
    "print(f\"Connected to: {ws.name} ({ws.location})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9ebeb9",
   "metadata": {},
   "source": [
    "# 2. Data Preparation\n",
    "\n",
    "Using [Retail data analytics](https://www.kaggle.com/datasets/manjeetsingh/retaildataset) - weekly sales by store and department."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485e5c30",
   "metadata": {},
   "source": [
    "## 2.1 Load Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a98900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stores: (45, 3)\n",
      "Features: (8190, 12)\n",
      "Sales: (421570, 5)\n",
      "\n",
      "--- Stores Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>202307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>37392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>205863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>34875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store Type    Size\n",
       "0      1    A  151315\n",
       "1      2    A  202307\n",
       "2      3    B   37392\n",
       "3      4    A  205863\n",
       "4      5    B   34875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Features Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>05/02/2010</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12/02/2010</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19/02/2010</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>26/02/2010</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>05/03/2010</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store        Date  Temperature  Fuel_Price  MarkDown1  MarkDown2  \\\n",
       "0      1  05/02/2010        42.31       2.572        NaN        NaN   \n",
       "1      1  12/02/2010        38.51       2.548        NaN        NaN   \n",
       "2      1  19/02/2010        39.93       2.514        NaN        NaN   \n",
       "3      1  26/02/2010        46.63       2.561        NaN        NaN   \n",
       "4      1  05/03/2010        46.50       2.625        NaN        NaN   \n",
       "\n",
       "   MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment  IsHoliday  \n",
       "0        NaN        NaN        NaN  211.096358         8.106      False  \n",
       "1        NaN        NaN        NaN  211.242170         8.106       True  \n",
       "2        NaN        NaN        NaN  211.289143         8.106      False  \n",
       "3        NaN        NaN        NaN  211.319643         8.106      False  \n",
       "4        NaN        NaN        NaN  211.350143         8.106      False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sales Data ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>05/02/2010</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12/02/2010</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19/02/2010</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26/02/2010</td>\n",
       "      <td>19403.54</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>05/03/2010</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept        Date  Weekly_Sales  IsHoliday\n",
       "0      1     1  05/02/2010      24924.50      False\n",
       "1      1     1  12/02/2010      46039.49       True\n",
       "2      1     1  19/02/2010      41595.55      False\n",
       "3      1     1  26/02/2010      19403.54      False\n",
       "4      1     1  05/03/2010      21827.90      False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "stores_df = pd.read_csv('../dataset/stores data-set.csv')\n",
    "features_df = pd.read_csv('../dataset/Features data set.csv')\n",
    "sales_df = pd.read_csv('../dataset/sales data-set.csv')\n",
    "\n",
    "# Quick exploration\n",
    "print(f\"Stores: {stores_df.shape}\")\n",
    "print(f\"Features: {features_df.shape}\")\n",
    "print(f\"Sales: {sales_df.shape}\")\n",
    "\n",
    "print(\"\\n--- Stores Data ---\")\n",
    "display(stores_df.head())\n",
    "\n",
    "print(\"\\n--- Features Data ---\")\n",
    "display(features_df.head())\n",
    "\n",
    "print(\"\\n--- Sales Data ---\")\n",
    "display(sales_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ffc88b",
   "metadata": {},
   "source": [
    "## 2.2 Merge Datasets\n",
    "Merge sales with stores (on Store) and then with features (on Store and Date).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fec8e293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset shape: (421570, 16)\n",
      "\n",
      "Columns: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday', 'Type', 'Size', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>05/02/2010</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12/02/2010</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>True</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19/02/2010</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26/02/2010</td>\n",
       "      <td>19403.54</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>05/03/2010</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept        Date  Weekly_Sales  IsHoliday Type    Size  Temperature  \\\n",
       "0      1     1  05/02/2010      24924.50      False    A  151315        42.31   \n",
       "1      1     1  12/02/2010      46039.49       True    A  151315        38.51   \n",
       "2      1     1  19/02/2010      41595.55      False    A  151315        39.93   \n",
       "3      1     1  26/02/2010      19403.54      False    A  151315        46.63   \n",
       "4      1     1  05/03/2010      21827.90      False    A  151315        46.50   \n",
       "\n",
       "   Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5  \\\n",
       "0       2.572        NaN        NaN        NaN        NaN        NaN   \n",
       "1       2.548        NaN        NaN        NaN        NaN        NaN   \n",
       "2       2.514        NaN        NaN        NaN        NaN        NaN   \n",
       "3       2.561        NaN        NaN        NaN        NaN        NaN   \n",
       "4       2.625        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "          CPI  Unemployment  \n",
       "0  211.096358         8.106  \n",
       "1  211.242170         8.106  \n",
       "2  211.289143         8.106  \n",
       "3  211.319643         8.106  \n",
       "4  211.350143         8.106  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge sales with stores (on Store)\n",
    "merged_df = sales_df.merge(stores_df, on='Store', how='left')\n",
    "\n",
    "# Merge with features (on Store and Date)\n",
    "merged_df = merged_df.merge(features_df, on=['Store', 'Date'], how='left', suffixes=('', '_feat'))\n",
    "\n",
    "# Drop duplicate IsHoliday column from features\n",
    "merged_df = merged_df.drop(columns=['IsHoliday_feat'])\n",
    "\n",
    "print(f\"Merged dataset shape: {merged_df.shape}\")\n",
    "print(f\"\\nColumns: {merged_df.columns.tolist()}\")\n",
    "display(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e3f01",
   "metadata": {},
   "source": [
    "## 2.3 Feature Engineering\n",
    "Create new features from date, handle missing MarkDown values, and encode categorical variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07d2b1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineered dataset: (421570, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Size</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>...</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>StoreType_A</th>\n",
       "      <th>StoreType_B</th>\n",
       "      <th>StoreType_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "      <td>151315</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>True</td>\n",
       "      <td>151315</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>False</td>\n",
       "      <td>151315</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>19403.54</td>\n",
       "      <td>False</td>\n",
       "      <td>151315</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>False</td>\n",
       "      <td>151315</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept       Date  Weekly_Sales  IsHoliday    Size  Temperature  \\\n",
       "0      1     1 2010-02-05      24924.50      False  151315        42.31   \n",
       "1      1     1 2010-02-12      46039.49       True  151315        38.51   \n",
       "2      1     1 2010-02-19      41595.55      False  151315        39.93   \n",
       "3      1     1 2010-02-26      19403.54      False  151315        46.63   \n",
       "4      1     1 2010-03-05      21827.90      False  151315        46.50   \n",
       "\n",
       "   Fuel_Price  MarkDown1  MarkDown2  ...  MarkDown5         CPI  Unemployment  \\\n",
       "0       2.572        0.0        0.0  ...        0.0  211.096358         8.106   \n",
       "1       2.548        0.0        0.0  ...        0.0  211.242170         8.106   \n",
       "2       2.514        0.0        0.0  ...        0.0  211.289143         8.106   \n",
       "3       2.561        0.0        0.0  ...        0.0  211.319643         8.106   \n",
       "4       2.625        0.0        0.0  ...        0.0  211.350143         8.106   \n",
       "\n",
       "   Year  Month  Week  DayOfWeek  StoreType_A  StoreType_B  StoreType_C  \n",
       "0  2010      2     5          4         True        False        False  \n",
       "1  2010      2     6          4         True        False        False  \n",
       "2  2010      2     7          4         True        False        False  \n",
       "3  2010      2     8          4         True        False        False  \n",
       "4  2010      3     9          4         True        False        False  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert Date to datetime (format is dd/mm/yyyy)\n",
    "merged_df['Date'] = pd.to_datetime(merged_df['Date'], dayfirst=True)\n",
    "\n",
    "# Extract date features\n",
    "merged_df['Year'] = merged_df['Date'].dt.year\n",
    "merged_df['Month'] = merged_df['Date'].dt.month\n",
    "merged_df['Week'] = merged_df['Date'].dt.isocalendar().week\n",
    "merged_df['DayOfWeek'] = merged_df['Date'].dt.dayofweek\n",
    "\n",
    "# Handle missing MarkDown values (only available after Nov 2011)\n",
    "markdown_cols = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
    "merged_df[markdown_cols] = merged_df[markdown_cols].fillna(0)\n",
    "\n",
    "# Encode categorical: Store Type (A, B, C)\n",
    "if 'Type' in merged_df.columns:\n",
    "    merged_df = pd.get_dummies(merged_df, columns=['Type'], prefix='StoreType')\n",
    "\n",
    "print(f\"Feature engineered dataset: {merged_df.shape}\")\n",
    "display(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f0205d",
   "metadata": {},
   "source": [
    "## 2.4 Time-Based Train/Validation Split\n",
    "\n",
    "Split data chronologically: train on data before 2012, validate on 2012 data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d5ab93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate combinations: 0\n",
      "After deduplication: (421570, 22)\n",
      "\n",
      "Training set: (294132, 22)\n",
      "Validation set: (127438, 22)\n",
      "Train date range: 2010-02-05 00:00:00 to 2011-12-30 00:00:00\n",
      "Validation date range: 2012-01-06 00:00:00 to 2012-10-26 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "dupes = merged_df.groupby(['Store', 'Dept', 'Date']).size()\n",
    "print(f\"Duplicate combinations: {(dupes > 1).sum()}\")\n",
    "\n",
    "# Aggregate duplicates: sum Weekly_Sales, take first for other columns\n",
    "agg_funcs = {col: 'first' for col in merged_df.columns if col not in ['Store', 'Dept', 'Date']}\n",
    "agg_funcs['Weekly_Sales'] = 'sum'\n",
    "merged_df = merged_df.groupby(['Store', 'Dept', 'Date'], as_index=False).agg(agg_funcs)\n",
    "print(f\"After deduplication: {merged_df.shape}\")\n",
    "\n",
    "# Sort by date\n",
    "merged_df = merged_df.sort_values(['Store', 'Dept', 'Date'])\n",
    "\n",
    "# Time-based split: train on data before 2012, validate on 2012\n",
    "train_df = merged_df[merged_df['Year'] < 2012].copy()\n",
    "validation_df = merged_df[merged_df['Year'] >= 2012].copy()\n",
    "\n",
    "print(f\"\\nTraining set: {train_df.shape}\")\n",
    "print(f\"Validation set: {validation_df.shape}\")\n",
    "print(f\"Train date range: {train_df['Date'].min()} to {train_df['Date'].max()}\")\n",
    "print(f\"Validation date range: {validation_df['Date'].min()} to {validation_df['Date'].max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00bca9",
   "metadata": {},
   "source": [
    "## 2.5 Prepare Data for Azure ML AutoML\n",
    "\n",
    "Rename columns to match AutoML expectations and save as MLTable format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 1: Filter to common time series ===\n",
      "Time series in training only: 0\n",
      "Time series in validation only: 0\n",
      "Common time series: 3187\n",
      "\n",
      "=== Step 2: Check contiguity (no gaps between train and validation) ===\n",
      "Contiguous time series: 2929\n",
      "Non-contiguous time series (will be removed): 258\n",
      "\n",
      "Sample non-contiguous series:\n",
      "  10_45: train ends 2011-12-09, val starts 2012-01-27 (gap: 49 days)\n",
      "  10_47: train ends 2011-11-18, val starts 2012-01-27 (gap: 70 days)\n",
      "  10_98: train ends 2011-12-30, val starts 2012-01-13 (gap: 14 days)\n",
      "  11_45: train ends 2011-12-23, val starts 2012-01-06 (gap: 14 days)\n",
      "  11_47: train ends 2011-09-09, val starts 2012-01-06 (gap: 119 days)\n",
      "  11_51: train ends 2011-05-06, val starts 2012-08-10 (gap: 462 days)\n",
      "  11_77: train ends 2011-12-09, val starts 2012-01-27 (gap: 49 days)\n",
      "  11_78: train ends 2010-11-12, val starts 2012-06-08 (gap: 574 days)\n",
      "  11_99: train ends 2011-12-30, val starts 2012-01-20 (gap: 21 days)\n",
      "  12_45: train ends 2011-12-30, val starts 2012-01-13 (gap: 14 days)\n",
      "\n",
      "=== Final Dataset ===\n",
      "Training time series: 2929\n",
      "Validation time series: 2929\n",
      "Training rows: 286072\n",
      "Validation rows: 124228\n",
      "Train duplicates: 0, Validation duplicates: 0\n",
      "\n",
      "Training data saved: 286072 rows\n",
      "Validation data saved: 124228 rows\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Rename columns for AutoML compatibility\n",
    "train_df = train_df.rename(columns={'Weekly_Sales': 'demand', 'Date': 'timeStamp'})\n",
    "validation_df = validation_df.rename(columns={'Weekly_Sales': 'demand', 'Date': 'timeStamp'})\n",
    "\n",
    "# Create single time series ID column (before converting dates to strings)\n",
    "train_df['ts_id'] = train_df['Store'].astype(str) + '_' + train_df['Dept'].astype(str)\n",
    "validation_df['ts_id'] = validation_df['Store'].astype(str) + '_' + validation_df['Dept'].astype(str)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Filter to common time series IDs (both train and validation must have same IDs)\n",
    "# ============================================================================\n",
    "train_ts_ids = set(train_df['ts_id'].unique())\n",
    "val_ts_ids = set(validation_df['ts_id'].unique())\n",
    "\n",
    "val_only_ids = val_ts_ids - train_ts_ids\n",
    "train_only_ids = train_ts_ids - val_ts_ids\n",
    "common_ids = train_ts_ids & val_ts_ids\n",
    "\n",
    "print(f\"=== Step 1: Filter to common time series ===\")\n",
    "print(f\"Time series in training only: {len(train_only_ids)}\")\n",
    "print(f\"Time series in validation only: {len(val_only_ids)}\")\n",
    "print(f\"Common time series: {len(common_ids)}\")\n",
    "\n",
    "# Keep only common IDs\n",
    "train_df = train_df[train_df['ts_id'].isin(common_ids)]\n",
    "validation_df = validation_df[validation_df['ts_id'].isin(common_ids)]\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 2: Check contiguity - validation must start right after training ends\n",
    "# For weekly data, the gap should be exactly 7 days\n",
    "# ============================================================================\n",
    "print(f\"\\n=== Step 2: Check contiguity (no gaps between train and validation) ===\")\n",
    "\n",
    "# Get max date per ts_id in training\n",
    "train_max_dates = train_df.groupby('ts_id')['timeStamp'].max().reset_index()\n",
    "train_max_dates.columns = ['ts_id', 'train_max_date']\n",
    "\n",
    "# Get min date per ts_id in validation\n",
    "val_min_dates = validation_df.groupby('ts_id')['timeStamp'].min().reset_index()\n",
    "val_min_dates.columns = ['ts_id', 'val_min_date']\n",
    "\n",
    "# Merge to compare\n",
    "contiguity_check = train_max_dates.merge(val_min_dates, on='ts_id')\n",
    "contiguity_check['train_max_date'] = pd.to_datetime(contiguity_check['train_max_date'])\n",
    "contiguity_check['val_min_date'] = pd.to_datetime(contiguity_check['val_min_date'])\n",
    "contiguity_check['gap_days'] = (contiguity_check['val_min_date'] - contiguity_check['train_max_date']).dt.days\n",
    "\n",
    "# For weekly data, gap should be 7 days (next week)\n",
    "# Allow some flexibility: 6-8 days is acceptable\n",
    "contiguity_check['is_contiguous'] = contiguity_check['gap_days'].between(6, 8)\n",
    "\n",
    "non_contiguous = contiguity_check[~contiguity_check['is_contiguous']]\n",
    "contiguous_ids = set(contiguity_check[contiguity_check['is_contiguous']]['ts_id'])\n",
    "\n",
    "print(f\"Contiguous time series: {len(contiguous_ids)}\")\n",
    "print(f\"Non-contiguous time series (will be removed): {len(non_contiguous)}\")\n",
    "\n",
    "if len(non_contiguous) > 0:\n",
    "    print(f\"\\nSample non-contiguous series:\")\n",
    "    sample = non_contiguous.head(10)\n",
    "    for _, row in sample.iterrows():\n",
    "        print(f\"  {row['ts_id']}: train ends {row['train_max_date'].date()}, val starts {row['val_min_date'].date()} (gap: {row['gap_days']} days)\")\n",
    "\n",
    "# Filter to only contiguous time series\n",
    "train_df = train_df[train_df['ts_id'].isin(contiguous_ids)]\n",
    "validation_df = validation_df[validation_df['ts_id'].isin(contiguous_ids)]\n",
    "\n",
    "print(f\"\\n=== Final Dataset ===\")\n",
    "print(f\"Training time series: {train_df['ts_id'].nunique()}\")\n",
    "print(f\"Validation time series: {validation_df['ts_id'].nunique()}\")\n",
    "print(f\"Training rows: {len(train_df)}\")\n",
    "print(f\"Validation rows: {len(validation_df)}\")\n",
    "\n",
    "# Convert timestamp to consistent date string format (no time component)\n",
    "train_df['timeStamp'] = pd.to_datetime(train_df['timeStamp']).dt.strftime('%Y-%m-%d')\n",
    "validation_df['timeStamp'] = pd.to_datetime(validation_df['timeStamp']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Verify no duplicates\n",
    "train_dupes = train_df.duplicated(subset=['ts_id', 'timeStamp']).sum()\n",
    "val_dupes = validation_df.duplicated(subset=['ts_id', 'timeStamp']).sum()\n",
    "print(f\"Train duplicates: {train_dupes}, Validation duplicates: {val_dupes}\")\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs('./data/training-mltable-folder', exist_ok=True)\n",
    "os.makedirs('./data/validation-mltable-folder', exist_ok=True)\n",
    "\n",
    "# Save as CSV (MLTable will reference these)\n",
    "train_df.to_csv('./data/training-mltable-folder/train.csv', index=False)\n",
    "validation_df.to_csv('./data/validation-mltable-folder/validation.csv', index=False)\n",
    "\n",
    "print(f\"\\nTraining data saved: {len(train_df)} rows\")\n",
    "print(f\"Validation data saved: {len(validation_df)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d9bcb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>demand</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Size</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>...</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>StoreType_A</th>\n",
       "      <th>StoreType_B</th>\n",
       "      <th>StoreType_C</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "      <td>151315</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>True</td>\n",
       "      <td>151315</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>False</td>\n",
       "      <td>151315</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>19403.54</td>\n",
       "      <td>False</td>\n",
       "      <td>151315</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>False</td>\n",
       "      <td>151315</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept   timeStamp    demand  IsHoliday    Size  Temperature  \\\n",
       "0      1     1  2010-02-05  24924.50      False  151315        42.31   \n",
       "1      1     1  2010-02-12  46039.49       True  151315        38.51   \n",
       "2      1     1  2010-02-19  41595.55      False  151315        39.93   \n",
       "3      1     1  2010-02-26  19403.54      False  151315        46.63   \n",
       "4      1     1  2010-03-05  21827.90      False  151315        46.50   \n",
       "\n",
       "   Fuel_Price  MarkDown1  MarkDown2  ...         CPI  Unemployment  Year  \\\n",
       "0       2.572        0.0        0.0  ...  211.096358         8.106  2010   \n",
       "1       2.548        0.0        0.0  ...  211.242170         8.106  2010   \n",
       "2       2.514        0.0        0.0  ...  211.289143         8.106  2010   \n",
       "3       2.561        0.0        0.0  ...  211.319643         8.106  2010   \n",
       "4       2.625        0.0        0.0  ...  211.350143         8.106  2010   \n",
       "\n",
       "   Month  Week  DayOfWeek  StoreType_A  StoreType_B  StoreType_C  ts_id  \n",
       "0      2     5          4         True        False        False    1_1  \n",
       "1      2     6          4         True        False        False    1_1  \n",
       "2      2     7          4         True        False        False    1_1  \n",
       "3      2     8          4         True        False        False    1_1  \n",
       "4      3     9          4         True        False        False    1_1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8316c32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>demand</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Size</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>...</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>StoreType_A</th>\n",
       "      <th>StoreType_B</th>\n",
       "      <th>StoreType_C</th>\n",
       "      <th>ts_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-06</td>\n",
       "      <td>16567.69</td>\n",
       "      <td>False</td>\n",
       "      <td>151315</td>\n",
       "      <td>49.01</td>\n",
       "      <td>3.157</td>\n",
       "      <td>6277.39</td>\n",
       "      <td>21813.16</td>\n",
       "      <td>...</td>\n",
       "      <td>219.714258</td>\n",
       "      <td>7.348</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>16894.40</td>\n",
       "      <td>False</td>\n",
       "      <td>151315</td>\n",
       "      <td>48.53</td>\n",
       "      <td>3.261</td>\n",
       "      <td>5183.29</td>\n",
       "      <td>8025.87</td>\n",
       "      <td>...</td>\n",
       "      <td>219.892526</td>\n",
       "      <td>7.348</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-20</td>\n",
       "      <td>18365.10</td>\n",
       "      <td>False</td>\n",
       "      <td>151315</td>\n",
       "      <td>54.11</td>\n",
       "      <td>3.268</td>\n",
       "      <td>4139.87</td>\n",
       "      <td>2807.19</td>\n",
       "      <td>...</td>\n",
       "      <td>219.985689</td>\n",
       "      <td>7.348</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-01-27</td>\n",
       "      <td>18378.16</td>\n",
       "      <td>False</td>\n",
       "      <td>151315</td>\n",
       "      <td>54.26</td>\n",
       "      <td>3.290</td>\n",
       "      <td>1164.46</td>\n",
       "      <td>1082.74</td>\n",
       "      <td>...</td>\n",
       "      <td>220.078852</td>\n",
       "      <td>7.348</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-02-03</td>\n",
       "      <td>23510.49</td>\n",
       "      <td>False</td>\n",
       "      <td>151315</td>\n",
       "      <td>56.55</td>\n",
       "      <td>3.360</td>\n",
       "      <td>34577.06</td>\n",
       "      <td>3579.21</td>\n",
       "      <td>...</td>\n",
       "      <td>220.172015</td>\n",
       "      <td>7.348</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Store  Dept   timeStamp    demand  IsHoliday    Size  Temperature  \\\n",
       "100      1     1  2012-01-06  16567.69      False  151315        49.01   \n",
       "101      1     1  2012-01-13  16894.40      False  151315        48.53   \n",
       "102      1     1  2012-01-20  18365.10      False  151315        54.11   \n",
       "103      1     1  2012-01-27  18378.16      False  151315        54.26   \n",
       "104      1     1  2012-02-03  23510.49      False  151315        56.55   \n",
       "\n",
       "     Fuel_Price  MarkDown1  MarkDown2  ...         CPI  Unemployment  Year  \\\n",
       "100       3.157    6277.39   21813.16  ...  219.714258         7.348  2012   \n",
       "101       3.261    5183.29    8025.87  ...  219.892526         7.348  2012   \n",
       "102       3.268    4139.87    2807.19  ...  219.985689         7.348  2012   \n",
       "103       3.290    1164.46    1082.74  ...  220.078852         7.348  2012   \n",
       "104       3.360   34577.06    3579.21  ...  220.172015         7.348  2012   \n",
       "\n",
       "     Month  Week  DayOfWeek  StoreType_A  StoreType_B  StoreType_C  ts_id  \n",
       "100      1     1          4         True        False        False    1_1  \n",
       "101      1     2          4         True        False        False    1_1  \n",
       "102      1     3          4         True        False        False    1_1  \n",
       "103      1     4          4         True        False        False    1_1  \n",
       "104      2     5          4         True        False        False    1_1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ea09bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLTable files created:\n",
      "  - ./data/training-mltable-folder/MLTable\n",
      "  - ./data/validation-mltable-folder/MLTable\n"
     ]
    }
   ],
   "source": [
    "mltable_train = \"\"\"paths:\n",
    "  - file: ./train.csv\n",
    "transformations:\n",
    "  - read_delimited:\n",
    "      delimiter: ','\n",
    "      header: all_files_same_headers\n",
    "\"\"\"\n",
    "\n",
    "mltable_val = \"\"\"paths:\n",
    "  - file: ./validation.csv\n",
    "transformations:\n",
    "  - read_delimited:\n",
    "      delimiter: ','\n",
    "      header: all_files_same_headers\n",
    "\"\"\"\n",
    "\n",
    "with open('./data/training-mltable-folder/MLTable', 'w') as f:\n",
    "    f.write(mltable_train)\n",
    "    \n",
    "with open('./data/validation-mltable-folder/MLTable', 'w') as f:\n",
    "    f.write(mltable_val)\n",
    "\n",
    "print(\"MLTable files created:\")\n",
    "print(\"  - ./data/training-mltable-folder/MLTable\")\n",
    "print(\"  - ./data/validation-mltable-folder/MLTable\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861505be",
   "metadata": {},
   "source": [
    "## 2.6 Upload Data to Azure Blob Storage\n",
    "\n",
    "Due to Azure Policy restrictions (SAS tokens disabled), data must be uploaded using Azure CLI with OAuth authentication.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c80df692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning retail-train-v2...\n",
      "Uploading ./data/training-mltable-folder to retail-train-v2...\n",
      "✓ Successfully uploaded to retail-train-v2\n",
      "  Output: [\n",
      "  {\n",
      "    \"Blob\": \"https://mldemowkspwus02609576373.blob.core.windows.net/azureml-blobstore-cff56e3a-d016-4526-aa58-71c460675066/retail-train-v2/MLTable\",\n",
      "    \"Last Modified\": \"2025-12-02T16:34:47+00:\n",
      "Cleaning retail-val-v2...\n",
      "Uploading ./data/validation-mltable-folder to retail-val-v2...\n",
      "✓ Successfully uploaded to retail-val-v2\n",
      "  Output: [\n",
      "  {\n",
      "    \"Blob\": \"https://mldemowkspwus02609576373.blob.core.windows.net/azureml-blobstore-cff56e3a-d016-4526-aa58-71c460675066/retail-val-v2/MLTable\",\n",
      "    \"Last Modified\": \"2025-12-02T16:34:51+00:00\n",
      "\n",
      "Data upload complete!\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Azure Storage configuration\n",
    "STORAGE_ACCOUNT = \"mldemowkspwus02609576373\"\n",
    "CONTAINER = \"azureml-blobstore-cff56e3a-d016-4526-aa58-71c460675066\"\n",
    "\n",
    "def upload_to_blob(source_folder, destination_path):\n",
    "    \"\"\"Upload local folder to Azure Blob Storage using OAuth authentication.\"\"\"\n",
    "    # First, delete existing data to ensure fresh upload\n",
    "    delete_cmd = [\n",
    "        \"az\", \"storage\", \"blob\", \"delete-batch\",\n",
    "        \"--account-name\", STORAGE_ACCOUNT,\n",
    "        \"--source\", CONTAINER,\n",
    "        \"--pattern\", f\"{destination_path}/*\",\n",
    "        \"--auth-mode\", \"login\"\n",
    "    ]\n",
    "    print(f\"Cleaning {destination_path}...\")\n",
    "    subprocess.run(delete_cmd, capture_output=True, text=True)\n",
    "    \n",
    "    # Upload new data\n",
    "    upload_cmd = [\n",
    "        \"az\", \"storage\", \"blob\", \"upload-batch\",\n",
    "        \"--account-name\", STORAGE_ACCOUNT,\n",
    "        \"--destination\", CONTAINER,\n",
    "        \"--destination-path\", destination_path,\n",
    "        \"--source\", source_folder,\n",
    "        \"--auth-mode\", \"login\",\n",
    "        \"--overwrite\"\n",
    "    ]\n",
    "    print(f\"Uploading {source_folder} to {destination_path}...\")\n",
    "    result = subprocess.run(upload_cmd, capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"✓ Successfully uploaded to {destination_path}\")\n",
    "        print(f\"  Output: {result.stdout[:200] if result.stdout else 'OK'}\")\n",
    "    else:\n",
    "        print(f\"✗ Upload failed: {result.stderr}\")\n",
    "    return result.returncode == 0\n",
    "\n",
    "# Upload training data to NEW path\n",
    "upload_to_blob(\"./data/training-mltable-folder\", \"retail-train-v2\")\n",
    "\n",
    "# Upload validation data to NEW path\n",
    "upload_to_blob(\"./data/validation-mltable-folder\", \"retail-val-v2\")\n",
    "\n",
    "print(\"\\nData upload complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecc993c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_training_data_input = Input(\n",
    "    type=AssetTypes.MLTABLE, \n",
    "    path=\"azureml://datastores/workspaceblobstore_identity/paths/retail-train-v2\"\n",
    ")\n",
    "\n",
    "my_validation_data_input = Input(\n",
    "    type=AssetTypes.MLTABLE, \n",
    "    path=\"azureml://datastores/workspaceblobstore_identity/paths/retail-val-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d929c4a9",
   "metadata": {},
   "source": [
    "# 3. Configure and Run AutoML Forecasting Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8836281",
   "metadata": {},
   "source": [
    "## 3.1 Job Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c77eb6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the AutoML forecasting job with the related factory-function.\n",
    "forecasting_job = automl.forecasting(\n",
    "    experiment_name=\"sales-forecasting-v2\",\n",
    "    compute=\"teslat4-gpu-wus\",  \n",
    "    training_data=my_training_data_input,\n",
    "    validation_data=my_validation_data_input, \n",
    "    target_column_name=\"demand\",\n",
    "    primary_metric=\"NormalizedRootMeanSquaredError\",\n",
    "    enable_model_explainability=True,\n",
    "    tags={\"retail\": \"forecasting\"},\n",
    ")\n",
    "\n",
    "# Limits are all optional\n",
    "forecasting_job.set_limits(\n",
    "    timeout_minutes=600,\n",
    "    trial_timeout_minutes=20,\n",
    "    max_trials=5,\n",
    "    enable_early_termination=True,\n",
    ")\n",
    "\n",
    "# Specialized properties for Time Series Forecasting training\n",
    "forecasting_job.set_forecast_settings(\n",
    "    time_column_name=\"timeStamp\",\n",
    "    forecast_horizon=12,  # 12 weeks forecast\n",
    "    frequency=\"W-FRI\",  # pandas offset: W-FRI=weekly anchored on Friday (matches our data)\n",
    "    time_series_id_column_names=[\"ts_id\"],\n",
    "    short_series_handling_config=\"auto\",  # Auto-handle short/irregular series\n",
    "    target_lags=\"auto\",\n",
    ")\n",
    "\n",
    "# forecasting_job.set_training(blocked_training_algorithms=[\"ExtremeRandomTrees\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16457be8",
   "metadata": {},
   "source": [
    "## 3.2 Submit Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40118475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created job: compute: azureml:teslat4-gpu-wus\n",
      "creation_context:\n",
      "  created_at: '2025-12-02T16:35:16.636410+00:00'\n",
      "  created_by: System Administrator\n",
      "  created_by_type: User\n",
      "display_name: ivory_egg_5t5nt4sff6\n",
      "experiment_name: sales-forecasting-v2\n",
      "forecasting:\n",
      "  feature_lags: none\n",
      "  forecast_horizon: 12\n",
      "  frequency: W-FRI\n",
      "  seasonality: auto\n",
      "  short_series_handling_config: auto\n",
      "  target_aggregate_function: none\n",
      "  target_lags: auto\n",
      "  time_column_name: timeStamp\n",
      "  time_series_id_column_names: '[''ts_id'']'\n",
      "  use_stl: none\n",
      "id: azureml:/subscriptions/57123c17-af1a-4ec2-9494-a214fb148bf4/resourceGroups/admin-rg/providers/Microsoft.MachineLearningServices/workspaces/ml-demo-wksp-wus-01/jobs/ivory_egg_5t5nt4sff6\n",
      "limits:\n",
      "  enable_early_termination: true\n",
      "  max_concurrent_trials: 1\n",
      "  max_cores_per_trial: -1\n",
      "  max_nodes: 1\n",
      "  max_trials: 5\n",
      "  timeout_minutes: 600\n",
      "  trial_timeout_minutes: 20\n",
      "log_verbosity: info\n",
      "name: ivory_egg_5t5nt4sff6\n",
      "outputs: {}\n",
      "primary_metric: normalized_root_mean_squared_error\n",
      "properties:\n",
      "  azureml.git.dirty: 'True'\n",
      "  mlflow.source.git.branch: main\n",
      "  mlflow.source.git.commit: 8fa296df1fd9649d3a06f6b28a7678eeba67546b\n",
      "  mlflow.source.git.repoURL: git@gh-personal:jimmyshah83/foundry-mcp-reservation-system.git\n",
      "queue_settings:\n",
      "  job_tier: 'null'\n",
      "resources:\n",
      "  instance_count: 1\n",
      "  shm_size: 2g\n",
      "services:\n",
      "  Studio:\n",
      "    endpoint: https://ml.azure.com/runs/ivory_egg_5t5nt4sff6?wsid=/subscriptions/57123c17-af1a-4ec2-9494-a214fb148bf4/resourcegroups/admin-rg/workspaces/ml-demo-wksp-wus-01&tid=c7b3a910-e2f8-4251-ac5c-d298df2d6e4e\n",
      "  Tracking:\n",
      "    endpoint: azureml://westus.api.azureml.ms/mlflow/v1.0/subscriptions/57123c17-af1a-4ec2-9494-a214fb148bf4/resourceGroups/admin-rg/providers/Microsoft.MachineLearningServices/workspaces/ml-demo-wksp-wus-01?\n",
      "status: NotStarted\n",
      "tags:\n",
      "  retail: forecasting\n",
      "target_column_name: demand\n",
      "task: forecasting\n",
      "training:\n",
      "  enable_dnn_training: false\n",
      "  enable_model_explainability: true\n",
      "  enable_onnx_compatible_models: false\n",
      "  enable_stack_ensemble: false\n",
      "  enable_vote_ensemble: true\n",
      "  ensemble_model_download_timeout_minutes: 5\n",
      "  training_mode: auto\n",
      "training_data:\n",
      "  path: azureml://datastores/workspaceblobstore_identity/paths/retail-train-v2\n",
      "  type: mltable\n",
      "type: automl\n",
      "validation_data:\n",
      "  path: azureml://datastores/workspaceblobstore_identity/paths/retail-val-v2\n",
      "  type: mltable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Submit the AutoML job\n",
    "returned_job = ml_client.jobs.create_or_update(forecasting_job)\n",
    "print(f\"Created job: {returned_job}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfa805a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: ivory_egg_5t5nt4sff6\n",
      "Web View: https://ml.azure.com/runs/ivory_egg_5t5nt4sff6?wsid=/subscriptions/57123c17-af1a-4ec2-9494-a214fb148bf4/resourcegroups/admin-rg/workspaces/ml-demo-wksp-wus-01\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: ivory_egg_5t5nt4sff6\n",
      "Web View: https://ml.azure.com/runs/ivory_egg_5t5nt4sff6?wsid=/subscriptions/57123c17-af1a-4ec2-9494-a214fb148bf4/resourcegroups/admin-rg/workspaces/ml-demo-wksp-wus-01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml_client.jobs.stream(returned_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8129921",
   "metadata": {},
   "source": [
    "# 4. Get Predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b636706",
   "metadata": {},
   "source": [
    "## 4.1 Download Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b90dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for the job to complete (if not already)\n",
    "from azure.ai.ml.entities import Model\n",
    "\n",
    "# Get the completed job details\n",
    "completed_job = ml_client.jobs.get(returned_job.name)\n",
    "print(f\"Job status: {completed_job.status}\")\n",
    "\n",
    "# Download the best model artifacts\n",
    "model_download_path = \"./outputs/best_model\"\n",
    "os.makedirs(model_download_path, exist_ok=True)\n",
    "\n",
    "ml_client.jobs.download(\n",
    "    name=returned_job.name,\n",
    "    download_path=\"./outputs\",\n",
    "    output_name=\"best_model\"\n",
    ")\n",
    "\n",
    "print(f\"Best model downloaded to: {model_download_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e08e102",
   "metadata": {},
   "source": [
    "## 4.2 Load Model and Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b922eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Load the downloaded model\n",
    "model_path = \"./outputs/best_model\"\n",
    "loaded_model = mlflow.pyfunc.load_model(model_path)\n",
    "\n",
    "print(f\"Model loaded successfully from: {model_path}\")\n",
    "print(f\"Model flavor: {loaded_model.metadata.flavors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare validation data for prediction (remove target column)\n",
    "prediction_input = validation_df.drop(columns=['demand']).copy()\n",
    "\n",
    "# Generate predictions\n",
    "predictions = loaded_model.predict(prediction_input)\n",
    "\n",
    "# Add predictions to validation dataframe\n",
    "validation_df['predicted_demand'] = predictions\n",
    "\n",
    "print(f\"Generated {len(predictions)} predictions\")\n",
    "display(validation_df[['Store', 'Dept', 'timeStamp', 'demand', 'predicted_demand']].head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f612aef4",
   "metadata": {},
   "source": [
    "## 4.3 Evaluate Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88be68b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "actual_tensor = torch.tensor(validation_df['demand'].values, dtype=torch.float32)\n",
    "predicted_tensor = torch.tensor(validation_df['predicted_demand'].values, dtype=torch.float32)\n",
    "\n",
    "# Calculate evaluation metrics using PyTorch\n",
    "# Mean Absolute Error (MAE)\n",
    "mae = torch.mean(torch.abs(actual_tensor - predicted_tensor)).item()\n",
    "\n",
    "# Root Mean Squared Error (RMSE)\n",
    "mse = torch.mean((actual_tensor - predicted_tensor) ** 2)\n",
    "rmse = torch.sqrt(mse).item()\n",
    "\n",
    "# R² Score\n",
    "ss_res = torch.sum((actual_tensor - predicted_tensor) ** 2)\n",
    "ss_tot = torch.sum((actual_tensor - torch.mean(actual_tensor)) ** 2)\n",
    "r2 = (1 - ss_res / ss_tot).item()\n",
    "\n",
    "# Mean Absolute Percentage Error (MAPE) - handle zeros\n",
    "non_zero_mask = actual_tensor != 0\n",
    "mape = torch.mean(torch.abs((actual_tensor[non_zero_mask] - predicted_tensor[non_zero_mask]) / actual_tensor[non_zero_mask])).item() * 100\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL EVALUATION METRICS (PyTorch)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mean Absolute Error (MAE):        ${mae:,.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE):   ${rmse:,.2f}\")\n",
    "print(f\"R² Score:                          {r2:.4f}\")\n",
    "print(f\"Mean Absolute % Error (MAPE):      {mape:.2f}%\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97837621",
   "metadata": {},
   "source": [
    "## 4.4 Save Predictions and Register Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d124cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV\n",
    "output_file = \"./outputs/predictions.csv\"\n",
    "os.makedirs(\"./outputs\", exist_ok=True)\n",
    "\n",
    "# Select relevant columns for output\n",
    "prediction_output = validation_df[['Store', 'Dept', 'timeStamp', 'demand', 'predicted_demand']].copy()\n",
    "prediction_output['error'] = prediction_output['demand'] - prediction_output['predicted_demand']\n",
    "prediction_output['absolute_error'] = abs(prediction_output['error'])\n",
    "\n",
    "prediction_output.to_csv(output_file, index=False)\n",
    "print(f\"Predictions saved to: {output_file}\")\n",
    "print(f\"Total predictions: {len(prediction_output)}\")\n",
    "\n",
    "# Show summary by store\n",
    "print(\"\\n--- Prediction Summary by Store (Top 10) ---\")\n",
    "store_summary = prediction_output.groupby('Store').agg({\n",
    "    'demand': 'sum',\n",
    "    'predicted_demand': 'sum',\n",
    "    'absolute_error': 'mean'\n",
    "}).round(2)\n",
    "store_summary.columns = ['Actual Sales', 'Predicted Sales', 'Avg Absolute Error']\n",
    "display(store_summary.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b305e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the best model in Azure ML Model Registry\n",
    "model = Model(\n",
    "    path=f\"azureml://jobs/{returned_job.name}/outputs/best_model\",\n",
    "    name=\"retail-sales-forecasting-model\",\n",
    "    description=\"AutoML time-series forecasting model for retail weekly sales\",\n",
    "    type=\"mlflow_model\"\n",
    ")\n",
    "\n",
    "registered_model = ml_client.models.create_or_update(model)\n",
    "print(f\"Registered model: {registered_model.name}, version: {registered_model.version}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
